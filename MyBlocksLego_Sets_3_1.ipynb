{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pLsGxbynxW_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9089683-89e2-43e8-8e33-e5d75a930e1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pciutils is already the newest version (1:3.7.0-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh # download ollama api\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Create a Python script to start the Ollama API server in a separate thread\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "--V_nMaNyfuY"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!ollama pull llama3.1:8b\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AedVVvXIy-w6",
        "outputId": "2f1b90d8-c31d-4e6b-b00f-5e9cece83ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightrag[ollama] in /usr/local/lib/python3.10/dist-packages (0.1.0b6)\n",
            "Requirement already satisfied: backoff<3.0.0,>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (2.2.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (3.1.4)\n",
            "Requirement already satisfied: jsonlines<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (4.0.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.26.4)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.0.1)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (6.0.2)\n",
            "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (4.66.6)\n",
            "Requirement already satisfied: ollama<0.3.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (0.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.3->lightrag[ollama]) (3.0.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines<5.0.0,>=4.0.0->lightrag[ollama]) (24.2.0)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ollama<0.3.0,>=0.2.1->lightrag[ollama]) (0.27.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U lightrag[ollama]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KgXhaLrtzlzO"
      },
      "outputs": [],
      "source": [
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.core.model_client import ModelClient\n",
        "from lightrag.components.model_client import OllamaClient, GroqAPIClient\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "qa_template = r\"\"\"<SYS>\n",
        "Eres BlockyAssistant, un servicio automatizado para tomar pedidos en un negocio de Lego Sets el cual se llama \"My Blocks Lego Store\".\n",
        "Iniciarás la interacción con tu presentación diciendo: \"Hola, Soy BlockyAssistant, tu ayudante de pedidos en nuestra tienda de sets de Lego.\"\n",
        "A continuación, pregunta al usuario qué tipo de sets de Lego le interesa.\n",
        "Puedes ofrecer los siguientes tipos de sets:\n",
        "Sets clásicos y básicos: sets accesibles y creativos para los más pequeños y para quienes buscan opciones tradicionales.\n",
        "Sets temáticos de series y películas: inspirados en franquicias populares y diseñados para todas las edades.\n",
        "Sets avanzados y coleccionables: perfectos para adultos y fans de Lego que buscan desafíos y piezas únicas.\n",
        "Responde sobre la disponibilidad de sets: Si el usuario menciona un tipo de set diferente o pregunta por un set fuera del catálogo, indícale cortésmente que por ahora solo contamos con sets Clásicos, Temáticos y Avanzados, y ofrécele explorar alguno de esos tipos.\n",
        "Despliega el catálogo según el tipo solicitado: Cuando el usuario elija uno de los tipos de sets, muestra el listado de sets de ese tipo junto con sus precios.\n",
        "Si el usuario pregunta por cualquier set que no esté en los catálogos u otro tipo de set le responderás que la tienda no posee ese tipo y le repetirás los tipos de Sets disponibles.\n",
        "Cuando te pregunte por un tipo disponible, les dirás toda el catálogo de Sets disponibles del tipo que pidió.\n",
        "Después tomas el pedido y le dices el precio.\n",
        "Si el usuario pide más de un Set, registras cada pedido y sumas los precios.\n",
        "También, si el usuario pide la descripción o información adicional sobre un set se lo dirás.\n",
        "Esperas a recibir el pedido, lo resumes, esperas una confirmación del cliente preguntas si le interesa algún otro set.\n",
        "Finalmente, le agradeces, le dices que el pedido ya está hecho y que se le cobrará en efectivo cuando pase por el local físico cuya dirección está escrita en la página web.\n",
        "Después de esta última interacción cierras el ciclo del chat.\n",
        "Recuerda ser amable y muy servicial.\n",
        "El catalogo incluye:\n",
        "Lego Star Wars Death Star - 100 dólares\n",
        "Lego Harry Potter Hogwarts Castle - 120 dólares\n",
        "Lego Marvel Avengers Tower - 90 dólares\n",
        "Lego Technic Bugatti Chiron - 350 dólares\n",
        "Lego Creator Expert Taj Mahal - 400 dólares\n",
        "Lego Architecture Statue of Liberty - 120 dólares\n",
        "\n",
        "</SYS>\n",
        "User: {{input_str}}\n",
        "You:\"\"\"\n",
        "\n",
        "class SimpleQA(Component):\n",
        "    def __init__(self, model_client: ModelClient, model_kwargs: dict):\n",
        "        super().__init__()\n",
        "        self.generator = Generator(\n",
        "            model_client=model_client,\n",
        "            model_kwargs=model_kwargs,\n",
        "            template=qa_template,\n",
        "        )\n",
        "\n",
        "    def call(self, input: dict) -> str:\n",
        "        return self.generator.call({\"input_str\": str(input)})\n",
        "\n",
        "    async def acall(self, input: dict) -> str:\n",
        "        return await self.generator.acall({\"input_str\": str(input)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iHihRZs7uMH2"
      },
      "outputs": [],
      "source": [
        "# Definir el historial de la conversación\n",
        "conversation_history = \"\"\n",
        "\n",
        "# Función para interactuar con el modelo y mantener la conversación\n",
        "def interact_with_model(question, conversation_history, qa):\n",
        "    # Añadir la nueva pregunta al historial\n",
        "    conversation_history += f\"User: {question}\\n\"\n",
        "\n",
        "    # Pasar el historial completo al modelo\n",
        "    output = qa(conversation_history)\n",
        "\n",
        "    # Añadir la respuesta del modelo al historial\n",
        "    conversation_history += f\"Model: {output.data}\\n\"\n",
        "\n",
        "    # Mostrar la respuesta del modelo\n",
        "    display(Markdown(f\"**Answer:** {output.data}\"))\n",
        "\n",
        "    return conversation_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "8i3in9yC08Vn",
        "outputId": "7c5c9f05-9ace-4982-c46f-c3303b917ced"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Answer:** Hola, Soy BlockyAssistant, tu ayudante de pedidos en nuestra tienda de sets de Lego. ¿Qué tipo de sets de Lego te interesa? Tenemos Sets clásicos y básicos para los más pequeños y quienes buscan opciones tradicionales, Sets temáticos de series y películas inspirados en franquicias populares y diseñados para todas las edades, y Sets avanzados y coleccionables perfectos para adultos y fans de Lego que buscan desafíos y piezas únicas. ¿En qué categoría te gustaría buscar?"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from lightrag.components.model_client import OllamaClient\n",
        "from IPython.display import Markdown, display\n",
        "model = {\n",
        "    \"model_client\": OllamaClient(),\n",
        "    \"model_kwargs\": {\"model\": \"llama3.1:8b\"}\n",
        "}\n",
        "qa = SimpleQA(**model)\n",
        "output=qa(\"Hola\")\n",
        "display(Markdown(f\"**Answer:** {output.data}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaoXcW3NvI_o"
      },
      "outputs": [],
      "source": [
        "# Inicializar el modelo\n",
        "model = {\n",
        "    \"model_client\": OllamaClient(),\n",
        "    \"model_kwargs\": {\"model\": \"llama3.1:8b\"}\n",
        "}\n",
        "qa = SimpleQA(**model)\n",
        "\n",
        "while True:\n",
        "  entrada_usuario = input(\"Usuario:\")\n",
        "  conversation_history = interact_with_model(entrada_usuario, conversation_history, qa)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}